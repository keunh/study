## 단일 서버
먼저 웹 앱, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행되는 케이스이다.
1. 사용자는 도메인 이름(api.mysite.com)을 이용해 웹사이트에 접속한다. 이 접속을 위해서는 도메인 이름을 도메인 이름 서비스(DNS)에 질의하여 IP 주소로 변환한다. DNS는 보통 제3 사업자(third party)가 제공하는 유료서비스를 이용하게 되므로, 우리 시스템의 일부는 아니다.
2. DNS 조회 결과로 IP가 반환된다. 
3. 해당 IP 주소로 HTTP(HyperText Transfer Protocol) 요청이 전달된다.
4. 요청을 받은 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환한다.

실제 요청처 2가지
- 웹 애플리케이션 : 비즈니스 로직, 데이터 저장 등은 서버 구현용 언어(자바, 파이썬 등)을 사용하고, 프레젠테이션용으로는 클라이언트 구현용 언어(HTML, 자바스크립트 등)을 사용한다.
- 모바일 앱: 모바일 앱과 웹 서버 간 통신을 위해서는 HTTP 프로토콜을 이용한다. 응답 데이터 포맷은JSON이 간결해 널리 쓰인다.

---

## 데이터베이스

사용자가 늘면 서버 하나로는 충분하지 않아서 여러 서버를 두어야 한다. 하나는 웹/모바일 트래픽 처리 서버(웹 계층), 다른 하나는 데이터베이스 서버(데이터 계층)이다.

- 어떤 데이터베이스를 사용할 것인가?
    - 관계형 데이터베이스
        - MySQL, 오라클, PostgreSQL 등이 있다.
    - 비 관계형 데이터베이스
        - CouchDB, Neo4j, Cassandra, HBase, Amazon DynamoDB 등이 있다.
        - NoSQL은 다시 네 부류로 나눌 수 있다.
            - 키-값 저장소(key-value store)
            - 그래프 저장소(graph store)
            - 칼럼 저장소(column store)
            - 문서 저장소(document store)
        - 일반적으로 조인 연산은 지원하지 않는다.
    - 대부분은 40년 이상 살아남은 관계형 데이터베이스가 최선일 것이다. 하지만 아래와 같은 경우에는 비 관계형 데이터베이스가 바람직할 수 있다.
        - 아주 낮은 응답 지연시간(latency)이 요구됨
        - 다루는 데이터가 비정형(unstructured)이라 관계형 데이터가 아님
        - 데이터(JSON, YAML, XML 등)를 직렬화하거나(serialize) 역직렬화(deserialize)할 수 있기만 하면 됨
        - 아주 많은 양의 데이터를 저장할 필요가 있음

---

## 수직적 규모 확장 vs 수평정 규모 확장

- (소위 스케일업)수직적 규모 확장(vertical scaling)은 서버에 고사양 자원(더 좋은 CPU, 더 많은 RAM 등)을 추가하는 것을 말한다.
- (소위 스케일 아웃)수평적 규모 확장은 더 많은 서버를 추가하여 성능을 개선하는 행위를 말한다.
- 서버로 유입되는 트래픽 양이 적을 때는 수직적 확장이 좋은 선택이며 단순함이 장점이지만, 단점이 있다.
    - 수직적 규모 확장에는 한계가 있다. 한 대의 서버에 CPU나 메모리를 무한대로 증설할 방법이 없다.
    - 장애에 대한 자동복구(failover) 방안, 다중화(redundancy) 방안을 제시하지 않는다. 서버에 장애가 발생하면 웹사이트/앱은 완전히 중단된다.
- 그래서 대규모 애플리케이션은 수평적 규모 확장법이 보다 적절하다.

### 로드밸런서
서버가 다운되면 사용자는 웹 사이트에 접속이 안된다. 너무 많은 사용자가 접속하여 서버가 한계에 도달하면 응답 속도가 느려지거나 서버 접속이 불가능해질 수 있다. 이런 문제를 해결하는 데 부하 분산기 또는 로드밸런서(load balancer)를 도입하는 것이 최선이다.

- 로드밸런서는 부하 분산 집합(load balancing set)에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다.
- (그림)
- 사용자는 로드밸런서의 공개 IP 주소로 접속한다. 서버 간 통신에는 사설 IP가 이용된다. 사설 IP 주소는 같은 네트워크에 속한 서버 사이의 통신에만 쓰이고, 인터넷을 통해서는 접속할 수 없다. 로드밸런서는 웹 서버와 통신하기 위해 바로 이 사설 주소를 이용한다.
- 부하 분산 집합에 웹 서버를 추가하면 장애를 복구하지 못하는 문제(no failover)는 해소되며, 웹 계층의 가용성(availability)은 향상된다.
    - 서버 1이 다운되면 모든 트래픽은 서버 2로 전송된다.
    - 웹 사이트로 유입되는 트래픽이 가파르게 증가하면 웹 서버 계층에 서버를 추가하기만 하면, 로드밸런스가 자동적으로 트래픽을 분산한다.

### 데이터베이스 다중화

- 많은 데이터베이스 관리 시스템이 다중화를 지원한다. 
- 보통은 서버 사이에 주(master)-부(slave) 관계를 설정하고 데이터 원본은 주 서버, 사본은 부 서버에 저장하는 방식이다.
- 주 데이터베이스에서만 쓰기 연산을 지원하고, 부 데이터베이스는 주 데이터베이스로부터 사본을 전달받으며, 읽기 연산만을 지원한다.
- 대부분 애플리케이션은 읽기 연산이 쓰기 연산보다 훨씬 높다. 그래서 통상 부 데이터베이스의 수가 주 데이터베이스 수보다 많다.

- 데이터베이스 다중화의 이점
    - 더 나은 성능 : 주-부 다중화 모델에서 모든 데이터 변경 연산은 주, 읽기 연산은 부 데이터베이스 서버로 분산된다. 병렬로 처리될 수 있는 질의(query) 수가 늘어나, 성능이 좋아진다.
    - 안정성(reliability): 자연 재해 등의 이유로 데이터베이스 서버 가운데 일부가 파괴되어도 데이터는 보존될 것이다. 지역적으로 여러 장소에 다중화시켜 놓을 수 있기 때문이다.
    - 가용성(availability) : 데이터를 여러 지역에 복제해 둠으로써 하나의 데이터베이스 서버에 장애가 발생하더라도 다른 서버에 있는 데이터를 가져와 계속 서비스할 수 있다.

### 데이터베이스 서버가 다운된다면?

- 부 서버가 한대 뿐인데 다운되었다면, 읽기 연산이 모두 주 서버로 전달될 것이다. 즉시 새로운 부 데이터베이스 서버가 장애 서버를 대체할 것이다. 부 서버가 여러대인 경우 읽기 연산은 나머지 부 서버들로 분산될 것이며, 새로운 부 데이터베이스 서버가 장애 서버를 대체할 것이다.
- 주 데이터베이스 서버가 다운되면, 한 대의 부 데이터베이스만 있는 경우 부 서버가 새로운 주 서버가 될 것이며, 모든 데이터베이스 연산은 일시적으로 새로운 주 서버상에서 수행될 것이다. 그리고 새로운 부 서버가 추가될 것이다.
- 실제 프로덕션 환경은 더 복잡하긴 하다. 부 서버 데이터가 최신 상태가 아닐 경우 없는 데이터는 복구 스크립트를 돌려 추가해야 한다. 다중 마스터(multi-masters)나 원형 다중화(circular replication) 방식을 도입하면 이런 상황에 대처하는데 도움될 수 있지만 구성이 훨씬 복잡하다. 참고 문헌 [4][5]를 확인하자.


### 로드밸런서와 데이터베이스 다중화

- 사용자는 DNS로부터 로드밸런서의 공개 IP 주소를 받는다.
- 사용자는 해당 IP 주소를 사용해 로드밸런서에 접속한다.
- HTTP 요청은 서버 1이나 서버 2로 전달된다.
- 웹 서버는 사용자의 데이터를 부 데이터베이스 서버에서 읽는다.
- 웹 서버는 데이터 변경 연산은 주 데이터베이스로 전달한다. 데이터 추가, 삭제, 갱신 연산 등이 이에 해당한다.

---

## 캐시

응답 시간(latency)은 캐시, 정적 콘텐츠는 CDN(Content Delivery Network, 콘텐츠 전송 네트워크)로 옮기면 개선할 수 있다.
캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 연이은 요청 시 캐시를 통해 더 빠르게 응답할 수 있다.

### 캐시 계층

- 캐시 계층은 데이터가 잠시 보관되는 곳으로 데이터베이스보다 훨씬 빠르다. 데이터베이스 부하 감소, 캐시 계층을 독립적으로 확장할 수 있다.

- 캐시 전략
  - 다양한 캐시 전략이 있는데, 캐시할 데이터 종류, 크기, 액세스 패턴에 맞는 캐시 전략을 선택하면 된다. 캐시 전략 비교 연구 결과는 [6]을 참조하자.
  - Cache-Aside
    - 애플리케이션이 직접 캐시를 관리한다. 먼저 캐시에서 데이터를 조회하고, 없으면 DB 조회 후 캐시에 저장한다.
    - 캐시에 저장하는 데이터 양을 줄일 수 있어 메모리 절약이 가능하지만, 처음 읽기는 느릴 수 있다.
  - Write-Through
    - 캐시와 DB에 데이터를 같이 저장하여, 항상 캐시에 최신 데이터가 존재한다. 읽기 성능은 빠르지만 쓰기 성능은 느릴 수 있다.
  - Write-Around
    - 바로 DB에 저장한다. 캐시에 쓰기 부하를 주지 않지만 캐시 미스가 발생한다.
  - Write-Back
    - 데이터가 먼저 캐시에 저장되고, 일정 시간 후 또는 특정 조건에서만 DB에 반영된다. 데이터 손실 위험이 있다. 
  - 주도형 캐시 전략(read-through caching strategy)
    - 캐시에 요청하면, 캐시가 직접 DB에서 데이터를 가져와 저장한다. Cache-Aside와 달리 애플리케이션이 직접 DB를 조회하지 않는다.
    - 애플리케이션이 캐시 로직을 신경 쓸 필요가 없지만 캐시가 직접 DB를 조회하므로 처리 시간이 길어질 수 있다.
  - Write-Behind 등이 있다.

### 캐시 사용 시 유의할 점

- 캐시는 어떤 상황에 바람직한가?
    - 데이터 갱신은 자주 없지만 참조가 빈번하게 일어나면 고려해볼만 하다.
- 어떤 데이터를 캐시에 두어야할까?
    - 캐시는 휘발성 메모리에 두므로, 영속 데이터는 캐시에 두지 않는 것이 좋다. 중요 데이터는 지속적 저장소(persistent data store)에 두어야 한다.
- 캐시에 보관된 데이터는 어떻게 만료(expire) 되는가?
    - 만료된 데이터는 캐시에서 삭제되어야 한다. 만료 기한이 너무 짧으면 데이터베이스를 너무 자주 읽을 것이고, 너무 길면 원본과 차이날 수 있다.
- 일관성(consistency)은 어떻게 유지되는가?
    - 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부다. 원본 갱신 연산과 캐시 갱신 연산이 단일 트랜잭션이 아니라면 일관성은 깨질 수 있다. 페이스북이 내놓은 논문 <Scaling Memcache at Facebook>[7]을 참고하자.
- 장애에는 어떻게 대처할 것인가?
    - 캐시 서버를 한 대만 둔다면 해당 서버는 단일 장애 지점(Single Point of Failure, SPOF)이 될 수 있다.(어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중단시킬 수 있는 경우 단일 장애 지점이라 부른다)
    - SPOF를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다.
- 캐시 메모리는 얼마나 크게 잡을 것인가?
    - 캐시 메모리가 너무 작으면 액세스 패턴에 따라서 데이터가 자주 eviction 되어 캐시 성능이 떨어진다. 이를 막기 위해 캐시 메모리를 과할당(overprivision) 한다. 캐시에 보관될 데이터가 갑자기 늘어날 경우의 문제도 방지할 수 있다.
- 데이터 방출(eviction) 정책은 무엇인가?
    - 캐시가 꽉 차면 추가로 캐시에 데이터를 넣기 위해 기존 데이터를 내보내야 한다. 널리 쓰이는 것은 LRU(Least Recently Used - 마지막으로 사용된 시점이 가장 오래된 데이터를 내보내는 정책)이다.
    - LFU(Least Frequently Used - 사용된 빈도가 가장 낮은 데이터를 내보내는 정책), FIFO(First In First Out - 가장 먼저 캐시에 들어온 데이터를 내보내는 정책) 등의 정책도 있다.

---

## 콘텐츠 전송 네트워크(CDN)

- CDN은 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크다. 이미지, 비디오, CSS, JavaScript 파일 등을 캐시할 수 있다. (동적 콘텐츠 캐싱은 다루지 않는다.)
- 간단히 요약하면 요청 경로(request path), query string, cookie, request header 등의 정보에 기반하여 HTML 페이지를 캐시하는 것이다(자세한건 [9]를 참고하자).
- 동작 방식
    - 어떤 사용자가 웹사이트에 방문하면, 그 사용자에게 가장 가까운 CDN 서버가 정적 콘텐츠를 전달한다. 사용자가 CDN 서버로부터 멀면 멀수록 웹사이트는 천천히 로드될 것이다.
    - CDN 동작 방식
      - (그림)
      1. 사용자 A가 이미지 URL을 이용해 image.png에 접근한다. URL 도메인은 CDN 서비스 사업자가 제공한 것이다. 아래 두 URL은 클라우드프론트(Cloudfront)와 아카마이(Akamai) CDN이 제공하는 URL의 예제다.
          - https://mysite.cloudfront.net/logo.jpg
          - https://mysite.akamai.com/image-manager/img/logo.jpg
      2. CDN 서버의 캐시에 해당 이미지가 없는 경우, 서버는 원본 (origin) 서버에 요청해 파일을 가져온다. 원본 서버는 웹 서버 또는 S3 같은 온라인 저장소 일 수 있다.
      3. 원본 서버가 파일을 CDN 서버에 반환한다. 응답의 HTTP 헤더에는 해당 파일이 얼마나 오래 캐시될 수 있는지를 설명하는 TTL 값이 있다.
      4. CDN 서버는 파일을 캐시하고 사용자 A에게 반환한다. 이미지는 TTL에 명시된 시간이 끝날 때까지 캐시된다.
      5. 사용자 B가 같은 이미지에 대한 요청을 CDN 서버에 전송한다.
      6. 만료되지 않은 이미지에 대한 요청은 캐시를 통해 처리된다.

### CDN 사용 시 고려해야 할 사항

- 비용
    - CDN은 보통 제3 사업자에 의해 운영되며, CDN으로 들어가고 나가는 데이터 전송 양에 따라 요금을 낸다. 자주 사용되지 않는 콘텐츠는 CDN에서 빼도 좋다.
- 적절한 만료 시한 설정
    - 만료 시점이 너무 길면 신선도가 떨어지고, 짧으면 원본 서버에 빈번히 접속하게 된다.
- CDN 장애났을 경우 해당 문제를 감지하여 원본 서버로부터 직접 콘텐츠를 가져오도록 클라이언트를 구성하는 것이 필요할 수도 있다.
- 콘텐츠 무효화(invalidation) 방법 : 아직 만료되지 않았더라도 아래 방법으로 CDN에서 제거할 수 있다.
    - CDN 서비스 사업자가 제공하는 API를 통해 콘텐츠 무효화
    - 콘텐츠의 다른 버전을 서비스하도록 오브젝터 버저닝(object versioning) 이용. 콘텐츠의 새로운 버전을 지정하기 위해서는 URL 마지막에 버전 번호를 인자로 주면 된다.

### CDN과 캐시가 추가된 설계

1. 정적 콘텐츠(JS, CSS, 이미지 등)는 더 이상 웹 서버를 통해 서비스하지 않으며, CDN을 통해 제공하여 더 나은 성능을 보장한다.
2. 캐시가 데이터베이스 부하를 줄여준다.

---

## 무상태(stateless) 웹 계층

- 웹 계층을 수평적으로 확장하는 방법. 웹 계층에서 상태 정보(사용자 세션 데이터 등)을 제거해야 한다.

### 상태 정보 의존적인 아키텍처

- 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 하는데, 대부분의 로드밸런서가 이를 지원하기 위해 고정 세션(sticky session)이라는 기능을 제공하지만 로드밸런서에 부담이 있다.
- 로드밸런서 뒷단에 서버를 추가하거나 제거하기도 까다롭다. 서버 장애를 처리하기도 복잡해진다.

### 무상태 아키텍처

- 사용자 요청은 어떤 웹 서버로도 전달될 수 있다. 웹 서버는 상태 정보가 필요한 경우 공유 저장소로부터 데이터를 가져온다.
- 구조는 단순하고, 안정적이며, 규모 확장이 쉽다.

### 무상태 서버 설계 완성도

- 공유 저장소는 관계형 데이터베이스 또는 캐시 시스템(Memcached/Redis) 또는 NoSQL 일 수 있다.
- 자동 규모 확장(autoscaling)은 트래픽 양에 따라 웹 서버를 자동으로 추가하거나 삭제하는 기능을 뜻한다.

---

## 데이터 센터

전 세계 서비스의 경우 가용성과 쾌적한 이용을 위해 여러 데이터 센터를 지원하는 것은 필수다.
사용자는 가장 가까운 데이터 센터로 안내되는데, 이를 지리적 라우팅(geoDNS-routing 또는 geo-routing)이라고 부른다. geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP 주소로 변환할지 결정해주는 DNS 서비스다.

- 데이터 센터 중 하나에 심각한 장애가 발생하면 모든 트래픽은 장애가 없는 데이터 센터로 전송되는데 이를 위해 몇 가지 기술이 필요하다.
    - 트래픽 우회 : GeoDNS는 사용자에게서 가장 가까운 데이터센터로 트래픽을 보낼 수 있도록 해준다.
    - 데이터 동기화 : 데이터 센터마다 별도의 데이터베이스를 사용한다면 장애 자동 복구(failover)로 트래픽이 다른 데이터베이스로 우회되더라도 다른 데이터센터에는 찾는 데이터가 없을 수 있다. 이를 위한 보편적 전략은 데이터를 여러 데이터센터에 걸쳐 다중화하는 것이다. (넷플릭스가 여러 데이터센터에 걸쳐 데이터를 어떻게 다중화하는지 관심이 있다면 [11]을 참고하자.)
    - 테스트와 배포 : 여러 데이터 센터를 사용한다면, 웹 사이트 또는 애플리케이션을 여러 위치에서 테스트해보는 것이 중요하다. 자동화된 배포 도구는 모든 데이터 센터에 동일한 서비스가 설치되는게 중요하다.

---

## 메시지 큐

메시지 큐는 메시지의 무손실(durability, 즉 메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성)을 보장하는, 비동기 통신을 지원하는 컴포넌트다.
메시지의 버퍼 역할을 하며, 비동기적으로 전송한다.
기본 아키텍처는 생산자 또는 발행자(producer/publisher)라고 불리는 입력 서비스가 메시지를 만들어 큐에 publish 한다. 큐에는 보통 소비자 혹은 구독자(consumer/subscriber)라 불리는 서비스가 연결되어 있고, 메시지를 받아 그에 맞는 동작을 수행한다.

- 메시지 큐를 사용하면 서비스 또는 서버 간 결합이 느슨해져, 규모 확장이 쉬워진다. 생산자는 소비자 프로세스가 다운되어도 메시지를 발행할 수 있고, 소비자는 생산자 서비스가 다운되어도 메시지를 수신할 수 있다.
  - 예로, 이미지의 cropping,  sharpening, blurring 등을 지원하는 사진 보정 애플리케이션을 만들 때 보정은 오래걸릴 수 있으니 비동기적으로 처리하면 편하다. 생산자와 소비자 서비스의 규모는 각기 독립적으로 확장될 수 있다. 큐가 커지면 처리기 프로세스 추가, 큐가 비어있다면 처리기 프로세스는 줄일 수 있을 것이다.

---

## 로그, 메트릭 그리고 자동화

- 로그 : 에러 로그를 모니터랑하는 것은 중요하다. 로그를 단일 서비스로 모아주는 도구를 활용하면 더 편리하다.
- 메트릭 : 메트릭을 잘 수집하면 사업 현황에 관한 유용한 정보를 얻을 수 있고, 시스템의 현재 상태를 쉽게 파악할 수도 있다.
    - 호스트 단위 메트릭 : CPU, 메모리, 디스크 I/O에 관한 메트릭
    - 종합(aggregated) 메트릭 : 데이터베이스 계층의 성능, 캐시 계층의 성능 등
    - 핵심 비즈니스 메트릭 : 일별 능동 사용자(daily active user), 수익(revenue), 재방문(retention) 등
- 자동화 : 시스템이 크고 복잡해지면 생산성을 높이기 위해 자동화 도구를 활용해야 한다. 지속적 통합(CI)을 도와주는 도구를 활용하면 어떤 검증 절차를 자동으로 거치도록 할 수 있다. 그외 빌드, 테스트, 베포 등을 자동화 할 수 있다.

---

## 메시지 큐, 로그, 메트릭, 자동화 등을 반영하여 수정한 설계안

1. 메시지 큐는 각 컴포넌트가 보다 느슨히 결합(loosely coupled) 될 수 있도록 하고, 결함에 대한 내성을 높인다.
2. 로그, 모니터링, 메트릭, 자동화 등을 지원하기 위한 장치를 추가하였다.

---

## 데이터베이스의 규모 확장

- 저장할 데이터가 많아지면 데이터베이스 증설 방법을 찾아야한다.
- 두 가지 접근법이 있는데 수직적 규모 확장법, 수평적 규모 확장법이 있다.

### 수직적 확장

- 기존 서버에 고성능의 자원(CPU, RAM, 디스크 등)을 증설하는 방법이다.
- 예로, 스택오버플로는 2013년 천만 명의 사용자 전부를 단 한 대의 마스터 데이터베이스로 처리했다.
- 하지만 약점이 있다.
    - 하드웨어에는 한계가 있으므로 CPU, RAM 등을 무한 증설할 수 없다.
    - SPOF(Single Point of Failure)로 인한 위험성이 크다.
    - 비용이 많이 든다.

### 수평적 확장

- 샤딩이라고도 부른다. 더 많은 서버를 추가한다.
- 샤딩은 대규모 데이터베이스를 샤드(shard)라고 부르는 작은 단위로 분할한다. 모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복이 없다.
- **샤딩 전략은 샤딩 키를 어떻게 정하는 지가 가장 중요하다.**
- **샤딩 키를 정할 때는 데이터를 고르게 분할할 수 있도록 하는게 가장 중요하다. 샤딩은 훌륭한 기술이지만 완벽하진 않다. 시스템이 복잡해지고 풀어야할 새로운 문제도 생긴다.**
- 데이터의 재 샤딩(resharding)이 필요한 경우
  - (1) 데이터가 너무 많아져서 하나의 샤드로 감당이 어려울 때. 
  - (2) 샤드 간 데이터 분포가 균등하지 못해 어떤 샤드에 할당된 공간 소모가 빨라질 때. 샤드 소진(shard exhaustion)이라 부르는데 샤드 키를 계산하는 함수를 변경하고 데이터를 재배치해야 한다. 5장의 안정 해시로 이 문제를 해결할 수 있다.
- 유명인사(celebrity) 문제
  - 핫스팟 키 문제.
  - 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제다.
  - 이 문제를 풀려면 유명인사 각각에 샤드 하나씩을 할당하거나, 더 잘게 쪼개야 할 수도 있다.
- 조인과 비정규화 (join and de-normalization)
  - 일단 하나의 데이터베이스를 여러 샤드 서버로 쪼개면, 여러 샤드에 걸친 데이터를 조인하기가 힘들어진다. 해결할 방법은 데이터베이스를 비정규화하여 하나의 테이블에서 질의가 수행될 수 있도록 하는 것이다.

### 데이터베이스 샤딩을 적용한 아키텍처

- 데이터베이스 부하를 줄이기 위해 관계형 데이터베이스가 요구되지 않는 기능은 NoSQL로 이전했다.
- NoSQL 다양한 활용 사례는 [14]를 참고하자.

---

## 백만 사용자, 그리고 그 이상

- 시스템 규모 확장은 지속적이고 반복적인 과정이다. 시스템을 최적화하고 더 작은 단위의 서비스로 분할해야 할 수도 있다.

---

## 정리
- 웹 계층은 무상태 계층으로
- 모든 계층에 다중화 도입
- 가능한 한 많은 데이터를 캐시할 것
- 여러 데이터 센터를 지원할 것
- 정적 콘텐츠는 CDN을 통해 서비스할 것
- 데이터 계층은 샤딩을 통해 그 규모를 확장할 것
- 각 계층은 독립적 서비스로 분할할 것
- 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것